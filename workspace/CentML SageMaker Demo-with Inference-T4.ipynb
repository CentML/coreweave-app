{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169a635b",
   "metadata": {},
   "source": [
    "# CentML Yoxall Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433dea6",
   "metadata": {},
   "source": [
    "In this demo we will use a <b>RESNET-50</b> model in ONNX format and optimize it with CentML using the CentML APIs. Once the ONNX model is optimized, we will compare the performance of the optimized model with the original format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8507f",
   "metadata": {},
   "source": [
    "## Export PyTorch Model to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60760d",
   "metadata": {},
   "source": [
    "We will use the open source Pytorch <b>RESNET-50</b> ONNX model for this demo\n",
    "We have also created a `param.json` which contains the following data about the input shape:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"input_shape\":\"1,3,224,224\",\n",
    "        \"dtype\":\"float16\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f278ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).eval().half().cuda()\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(torch.float16).cuda()\n",
    "\n",
    "input_names = [ \"actual_input\" ]\n",
    "output_names = [ \"output\" ]\n",
    "torch.onnx.export(model,\n",
    "                 dummy_input,\n",
    "                 \"./model.onnx\",\n",
    "                 verbose=False,\n",
    "                 input_names=input_names,\n",
    "                 output_names=output_names,\n",
    "                 export_params=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb6f253",
   "metadata": {},
   "source": [
    "## Upload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274aa8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=\"us-east-1\")\n",
    "default_bucket = sagemaker.session.Session().default_bucket()\n",
    "\n",
    "# Change model name here\n",
    "MODEL_NAME = \"resnet50\"\n",
    "\n",
    "# Set path to ONNX file\n",
    "path_to_onnx = './model.onnx'\n",
    "\n",
    "# Set path to params.json file\n",
    "path_to_params = \"./params.json\"\n",
    "\n",
    "\n",
    "s3_client.upload_file(path_to_onnx, default_bucket, f\"{MODEL_NAME}/model.onnx\")\n",
    "s3_client.upload_file(path_to_params, default_bucket, f\"{MODEL_NAME}/params.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd08153",
   "metadata": {},
   "source": [
    "## Submit optimize request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572c94ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training job {'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:725137708992:training-job/resnet50-16803151213335679', 'ResponseMetadata': {'RequestId': '92e6b96e-5287-452f-85a7-bb00ea848b39', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '92e6b96e-5287-452f-85a7-bb00ea848b39', 'content-type': 'application/x-amz-json-1.1', 'content-length': '101', 'date': 'Sat, 01 Apr 2023 02:12:00 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "s3_client = boto3.client(\"s3\", region_name=\"us-east-1\")\n",
    "default_bucket = sagemaker.session.Session().default_bucket()\n",
    "\n",
    "# Select hardware from https://aws.amazon.com/sagemaker/pricing/\n",
    "instance = \"ml.g4dn.2xlarge\" # T4 instance\n",
    "MODEL_NAME = \"resnet50\"\n",
    "\n",
    "client = boto3.client('sagemaker', region_name=\"us-east-1\")\n",
    "\n",
    "training_job_name = f'{MODEL_NAME}-{str(time.time()).replace(\".\", \"\")}'\n",
    "\n",
    "response = client.create_training_job(\n",
    "    TrainingJobName=training_job_name,\n",
    "    AlgorithmSpecification={\n",
    "        'TrainingImage': '725137708992.dkr.ecr.us-east-1.amazonaws.com/centml:latest',\n",
    "        'TrainingInputMode': 'File',\n",
    "    },\n",
    "    RoleArn='arn:aws:iam::725137708992:role/centml-yoxall-sageMakerRole-dev',\n",
    "    InputDataConfig=[\n",
    "        {\n",
    "            'ChannelName': 'model',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'S3Prefix',\n",
    "                    'S3Uri': f's3://{default_bucket}/{MODEL_NAME}/model.onnx',\n",
    "                    'S3DataDistributionType': 'FullyReplicated',\n",
    "                },\n",
    "            },\n",
    "            \"ContentType\": \"application/octet-stream\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"InputMode\": \"File\"\n",
    "        },\n",
    "        {    \n",
    "            \"ChannelName\": \"params\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": f\"s3://{default_bucket}/{MODEL_NAME}/params.json\",\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",    \n",
    "                },\n",
    "            },\n",
    "            \"ContentType\": \"application/json\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"InputMode\": \"File\"\n",
    "        }\n",
    "    ],\n",
    "    OutputDataConfig={\n",
    "        'S3OutputPath': f's3://{default_bucket}/outputs/'\n",
    "    },\n",
    "    ResourceConfig={\n",
    "        'InstanceType': instance,\n",
    "        'InstanceCount': 1,\n",
    "        'VolumeSizeInGB': 225,\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        \"MaxRuntimeInSeconds\": 86400\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Created training job {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae5c275",
   "metadata": {},
   "source": [
    "##  Check status of optimization job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c93fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization job status: Completed\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker\", region_name=\"us-east-1\")\n",
    "training_job_name = \"resnet50-16801275426092536\"\n",
    "# Get sagemaker job status\n",
    "response = client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "status = response[\"TrainingJobStatus\"]\n",
    "\n",
    "print(f\"Optimization job status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdbab61",
   "metadata": {},
   "source": [
    "## Wait for optimize to finish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f456742",
   "metadata": {},
   "source": [
    "<b>An optimization task can take upto several hours.</b>\n",
    "We can check the status of a optimization job with the status API using the optimization task id from above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48194828",
   "metadata": {},
   "source": [
    "## Download optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f744d910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-725137708992/outputs/resnet50-16801275426092536/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import tarfile\n",
    "\n",
    "response = client.describe_training_job(TrainingJobName=training_job_name)\n",
    "status = response[\"TrainingJobStatus\"]\n",
    "assert status == \"Completed\", \"Optimization job failed or is still in progress\"\n",
    "\n",
    "downloadUrl = response[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "!aws s3 cp {downloadUrl} .\n",
    "\n",
    "# open file\n",
    "file = tarfile.open('model.tar.gz')\n",
    "  \n",
    "# extracting file\n",
    "file.extractall('./model')\n",
    "  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f9324",
   "metadata": {},
   "source": [
    "## Load optimized model and run CentML benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baad4b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 0.0024s\n",
      "CPU times: user 2.97 s, sys: 380 ms, total: 3.35 s\n",
      "Wall time: 9.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import erin\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set file paths\n",
    "params = \"params.json\"\n",
    "onnx_path = \"model.onnx\"\n",
    "\n",
    "# Set the model in Hidet/Erin\n",
    "model = erin.create_model(onnx_path, params, './model')\n",
    "\n",
    "np_payload = np.random.rand(1,3,224, 224).astype(\"float16\")\n",
    "hidet_tensor = erin.from_numpy(np_payload).cuda()\n",
    "\n",
    "# Configure number of iterations to run here\n",
    "NUM_ITERATIONS = 100\n",
    "\n",
    "hidet_time_durations = []\n",
    "for i in range(0,NUM_ITERATIONS):\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Prediction tensor\n",
    "    output = model.predict(hidet_tensor)\n",
    "    \n",
    "    #End time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    hidet_time_durations.append(duration)\n",
    "\n",
    "print(\"Average time: {:0.4f}s\".format(sum(hidet_time_durations)/len(hidet_time_durations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c571c8",
   "metadata": {},
   "source": [
    "## Run PyTorch benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b297264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 0.0102s\n",
      "CPU times: user 2.02 s, sys: 90.7 ms, total: 2.11 s\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).eval().half().cuda()\n",
    "pytorch_tensor = torch.from_numpy(np_payload).cuda()\n",
    "\n",
    "pytorch_time_durations = []\n",
    "\n",
    "for i in range(0, NUM_ITERATIONS):\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Prediction tensor\n",
    "    output = model(pytorch_tensor)\n",
    "    \n",
    "    #End time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    pytorch_time_durations.append(duration)\n",
    "\n",
    "print(\"Average time: {:0.4f}s\".format(sum(pytorch_time_durations)/len(pytorch_time_durations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4137e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
