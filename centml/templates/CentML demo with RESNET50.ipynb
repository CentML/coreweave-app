{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169a635b",
   "metadata": {},
   "source": [
    "# CentML Yoxall Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433dea6",
   "metadata": {},
   "source": [
    "In this demo we will use a <b>RESNET-50</b> model in ONNX format and optimize it with CentML using the CentML APIs. Once the ONNX model is optimized, we will compare the performance of the optimized model with the original format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8507f",
   "metadata": {},
   "source": [
    "## Export PyTorch Model to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60760d",
   "metadata": {},
   "source": [
    "We will use the open source Pytorch <b>RESNET-50</b> ONNX model for this demo\n",
    "We have also created a `param.json` which contains the following data about the input shape:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"input_shape\":\"1,3,224,224\",\n",
    "        \"dtype\":\"float16\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f278ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).eval().half().cuda()\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(torch.float16).cuda()\n",
    "\n",
    "input_names = [ \"actual_input\" ]\n",
    "output_names = [ \"output\" ]\n",
    "torch.onnx.export(model,\n",
    "                 dummy_input,\n",
    "                 \"./model.onnx\",\n",
    "                 verbose=False,\n",
    "                 input_names=input_names,\n",
    "                 output_names=output_names,\n",
    "                 export_params=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb6f253",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274aa8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from erin_server.optimize import optimize\n",
    "\n",
    "optimize(onnx_path=\"./model.onnx\",\n",
    "         params_file=\"./params.json\",\n",
    "         outdir=\"./output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdbab61",
   "metadata": {},
   "source": [
    "## Wait for optimize to finish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f456742",
   "metadata": {},
   "source": [
    "<b>An optimization task can take upto several hours.</b>\n",
    "We can check the status of a optimization job with the status API using the optimization task id from above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f9324",
   "metadata": {},
   "source": [
    "## Load optimized model and run CentML benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import erin\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set file paths\n",
    "params = \"./params.json\"\n",
    "onnx_path = \"./model.onnx\"\n",
    "\n",
    "# Set the model in Hidet/Erin\n",
    "model = erin.create_model(onnx_path, params, './model')\n",
    "\n",
    "np_payload = np.random.rand(1,3,224, 224).astype(\"float16\")\n",
    "hidet_tensor = erin.from_numpy(np_payload).cuda()\n",
    "\n",
    "# Configure number of iterations to run here\n",
    "NUM_ITERATIONS = 100\n",
    "\n",
    "hidet_time_durations = []\n",
    "for i in range(0,NUM_ITERATIONS):\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Prediction tensor\n",
    "    output = model.predict(hidet_tensor)\n",
    "    \n",
    "    #End time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    hidet_time_durations.append(duration)\n",
    "\n",
    "print(\"Average time: {:0.4f}s\".format(sum(hidet_time_durations)/len(hidet_time_durations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c571c8",
   "metadata": {},
   "source": [
    "## Run PyTorch benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).eval().half().cuda()\n",
    "pytorch_tensor = torch.from_numpy(np_payload).cuda()\n",
    "\n",
    "pytorch_time_durations = []\n",
    "\n",
    "for i in range(0, NUM_ITERATIONS):\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Prediction tensor\n",
    "    output = model(pytorch_tensor)\n",
    "    \n",
    "    #End time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    pytorch_time_durations.append(duration)\n",
    "\n",
    "print(\"Average time: {:0.4f}s\".format(sum(pytorch_time_durations)/len(pytorch_time_durations)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
